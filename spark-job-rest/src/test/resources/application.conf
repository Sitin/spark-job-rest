# spark default configuration
spark.executor.memory=2g
spark.mesos.coarse=false
spark.scheduler.mode=FAIR
spark.cores.max=2
spark.master="local"
spark.path=${SPARK_HOME}
spark.default.parallelism=384
spark.storage.memoryFraction=0.3
spark.shuffle.memoryFraction=0.6
spark.shuffle.compress=true
spark.shuffle.spill-compress=true
spark.reducer.maxMbInFlight=48
spark.akka.frameSize=100
spark.akka.threads=4
spark.akka.timeout=100
spark.task.maxFailures=4
spark.shuffle.consolidateFiles=true
spark.deploy.spreadOut=true
spark.shuffle.spill=false
spark.kryo.referenceTracking=false

#Default Spark Driver JVM memory
driver.xmxMemory = 1g

#
# Root config node for all Spark-Job-REST configuration
#
spark.job.rest {
  #
  # Application configuration
  #
  appConf {
    # This ip on which to deploy the apis
    web.services.ip="0.0.0.0"
    # The port on which to deploy the apis
    web.services.port=8097
    # Implicit akka timeout
    timeout=1000000
    # The port where the range for actor system starts
    actor.systems.first.port = 11000
    # The port where the range for spark ui starts
    spark.ui.first.port = 16000
    # The path to the folder where to keep the jars
    jars.path = /tmp/spark-job-rest/jars
  }

  #
  # Database settings
  #
  database {
    # Database default port
    port = 9192
    # Default host
    host = "localhost"
    # Default database name
    name = "spark-job-rest-db"
    # Database directory location
    baseDir = "db"
  }

  #
  # Duration properties (includung retries, timeouts and intervals)
  #
  durations {
    # Actor communication
    ask {
      # Ask timeout (milliseconds)
      timeout = 20000
    }
    # Actor initialisation
    init {
      # Ask timeout (milliseconds)
      timeout = 1000
      # How many times to try to get heartbeat from actor
      tries = 10
    }
    # Remote context initialization
    context {
      # Implicit sleep (milliseconds) before sending init message
      sleep = 3000
      # Tries before consider remote context as dead
      tries = 20
      # Timeout for each attempt (milliseconds)
      retry-timeout = 1000
      # Inteval beetween attempts to reach remote context (milliseconds)
      retry-interval = 1500
    }
    # Database properties
    db {
      # Timeout for database initialization (milliseconds)
      initialization-timeout = 15000
      # Database operation timeout (milliseconds)
      timeout = 5000
      # Database connection initialisation
      connection {
        # Ask timeout (milliseconds)
        timeout = 1000
        # How many times to try to get connection from connection provider
        tries = 10
      }
    }
  }

  #
  # Context properties
  #
  context {
    # Path to context process work directory
    contexts-base-dir = /tmp/spark-job-rest/contexts
    # Context factory that will be dynamically loaded to instantiate job context
    job-context-factory = "context.SparkContextFactory"
  }

  #
  # Main application properties
  #
  manager {
    akka {
      log-dead-letters = 1
      actor {
        provider = "akka.remote.RemoteActorRefProvider"
      }
      remote {
        log-remote-lifecycle-events = off
        enabled-transports = ["akka.remote.netty.tcp"]
        log-sent-messages = on
        log-received-messages = on
        netty.tcp {
          transport-class = "akka.remote.transport.netty.NettyTransport"
          hostname = "127.0.0.1"
          port = 4042
          maximum-frame-size = 256000b
        }
      }
    }

    spray.can.server {
      # uncomment the next line for making this an HTTPS example
      # ssl-encryption = on
      idle-timeout = 61 s
      request-timeout = 60 s
      parsing.max-content-length = 200m
    }
  }
}
